{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "21tDGlpnyIgn",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install astroquery photutils\n",
    "# !conda install -c conda-forge astroquery phototils\n",
    "# # If you do not:\n",
    "# !git clone https://github.com/astropy/astroquery.git\n",
    "# !cd astroquery phototils\n",
    "# !python setup.py install\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "ZQ6_sk5kyFAn",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "from scipy.spatial import KDTree\n",
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "from astroquery.skyview import SkyView\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from photutils.detection import IRAFStarFinder\n",
    "from photutils.aperture import CircularAperture\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from astropy.wcs import FITSFixedWarning\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDwzJXYa9IHN"
   },
   "outputs": [],
   "source": [
    "# Загрузка Parquet-файлов каталогов\n",
    "\n",
    "def upload_file(filename, prompt, columns_names):\n",
    "\n",
    "    print(prompt)\n",
    "    \n",
    "    df = pl.read_parquet(filename)\n",
    "    \n",
    "    if len(df.columns) != len(columns_names):\n",
    "        raise ValueError(f\"Число колонок в файле ({len(df.columns)}) не совпадает с числом имен ({len(columns_names)})\")\n",
    "    \n",
    "    rename_dict = {old: new for old, new in zip(df.columns, columns_names)}\n",
    "    df = df.rename(rename_dict)\n",
    "    \n",
    "    if len(columns_names) == 9:  # Для coords_catalog\n",
    "        schema_overrides = {\n",
    "            'X': pl.Float64,\n",
    "            'Y': pl.Float64,\n",
    "            'Gmag': pl.Float64,\n",
    "            'RA': pl.Float64,\n",
    "            'Dec': pl.Float64,\n",
    "            'RA_IRAF': pl.Float64,\n",
    "            'Dec_IRAF': pl.Float64,\n",
    "            'Name_a': pl.Float64,\n",
    "            'Name_b': pl.Float64\n",
    "        }\n",
    "    elif len(columns_names) == 5:  # Для dists_catalog\n",
    "        schema_overrides = {\n",
    "            'Distance': pl.Float64,\n",
    "            'Name1_a': pl.Float64,\n",
    "            'Name1_b': pl.Float64,\n",
    "            'Name2_a': pl.Float64,\n",
    "            'Name2_b': pl.Float64\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Неподдерживаемое число колонок: {len(columns_names)}\")\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        pl.col(col).cast(dtype) for col, dtype in schema_overrides.items()\n",
    "    ])\n",
    "    \n",
    "    return df, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tinynDYM9IHS"
   },
   "outputs": [],
   "source": [
    "# Функция расстояния в пикселях\n",
    "def calculate_distance(x1_pix, y1_pix, x2_pix, y2_pix):\n",
    "    return np.sqrt((x1_pix - x2_pix)**2 + (y1_pix - y2_pix)**2)\n",
    "\n",
    "def get_random_in_square(x_min, x_max, y_min, y_max):\n",
    "    x = round(random.uniform(x_min, x_max), 1)\n",
    "    y = round(random.uniform(y_min, y_max), 1)\n",
    "    return x, y\n",
    "\n",
    "# Конвертация Astropy Table в Polars DF\n",
    "def qtable_to_polars(qtable):\n",
    "    data_dict = {}\n",
    "    for col_name in qtable.colnames:\n",
    "        column = qtable[col_name]\n",
    "        data_dict[col_name] = column.value if hasattr(column, 'value') else column.data\n",
    "    df = pl.DataFrame(data_dict)\n",
    "    if hasattr(qtable, 'meta') and qtable.meta:\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "# Загрузка изображения\n",
    "def get_image(ra, dec, rad, pix, cat):\n",
    "    fites = SkyView.get_images(position=f\"{ra}, {dec}\", survey=[cat], pixels=pix, projection='Tan', radius=rad * u.deg)[0][0]\n",
    "    return fites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lcitq5WR9IHU"
   },
   "outputs": [],
   "source": [
    "# Поиск фотоцентров на изображении\n",
    "\n",
    "def find_stars_on_image(image, fwhm=10.0, threshold_factor=3.0,  some_flux_threshold=50, plot_results=False):\n",
    "    data = image.data\n",
    "    mean, median, std = sigma_clipped_stats(data, sigma=2.0)\n",
    "    finder = IRAFStarFinder(fwhm=fwhm, threshold=threshold_factor * std,\n",
    "                            sharplo=0.2, sharphi=1.5,\n",
    "                            roundlo=-1.0, roundhi=1.0,\n",
    "                            peakmax=50000,\n",
    "                            exclude_border=True, sigma_radius=2.0)\n",
    "    sources = finder(data - median)\n",
    "\n",
    "    if sources is not None:\n",
    "        sources.sort('flux', reverse=True)\n",
    "        bright_sources = sources[: some_flux_threshold]  # Топ-50 ярких\n",
    "        print(f\"Bright stars found (top { some_flux_threshold}): {len(bright_sources)}\")\n",
    "\n",
    "        if plot_results:\n",
    "            positions = np.transpose((bright_sources['xcentroid'], bright_sources['ycentroid']))\n",
    "            plt.imshow(data, cmap='gray', origin='lower')\n",
    "            apertures = CircularAperture(positions, r=8.)\n",
    "            apertures.plot(color='red', lw=1.5, alpha=0.7)\n",
    "            plt.show()\n",
    "\n",
    "        return bright_sources\n",
    "    else:\n",
    "        print(\"No stars found!\")\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка пар\n",
    "\n",
    "def sort_sources(sources_table, scale, theta_max, use_kdtree=False):\n",
    "    if len(sources_table) > 1:\n",
    "        ids = sources_table['id'].to_numpy()\n",
    "        x = sources_table['xcentroid'].to_numpy()\n",
    "        y = sources_table['ycentroid'].to_numpy()\n",
    "        flux = sources_table['flux'].to_numpy()\n",
    "    \n",
    "        if use_kdtree:\n",
    "            pixel_max = theta_max / scale\n",
    "            tree = KDTree(np.column_stack((x, y)))\n",
    "            pairs = tree.query_pairs(r=pixel_max, output_type='ndarray')\n",
    "            i, j = pairs[:, 0], pairs[:, 1]\n",
    "        else:\n",
    "            pairs = list(combinations(range(len(sources_df)), 2))\n",
    "            i = np.array([p[0] for p in pairs])\n",
    "            j = np.array([p[1] for p in pairs])\n",
    "    \n",
    "        distance_pix = calculate_distance(x[i], y[i], x[j], y[j])\n",
    "        distance_deg = distance_pix * scale\n",
    "        total_brightness = flux[i] + flux[j]\n",
    "    \n",
    "        mask = (distance_pix >= fwhm) & (distance_deg <= theta_max)\n",
    "        filtered_i = ids[i[mask]]\n",
    "        filtered_j = ids[j[mask]]\n",
    "        filtered_dist = distance_deg[mask]\n",
    "        filtered_bright = total_brightness[mask]\n",
    "    \n",
    "        unsorted_pairs = pl.DataFrame({\n",
    "            'id1': filtered_i,\n",
    "            'id2': filtered_j,\n",
    "            'distance': filtered_dist,\n",
    "            'total_brightness': filtered_bright\n",
    "        })\n",
    "    \n",
    "        sorted_sources = unsorted_pairs.sort('total_brightness', descending=True)\n",
    "\n",
    "        return sorted_sources\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные функции\n",
    "\n",
    "def find_duplicates(a, b, c, d):\n",
    "    values = set([a, b, c, d])\n",
    "    duplicates = [x for x in [a, b] if x in [c, d]]\n",
    "    uniques = list(values - set(duplicates))\n",
    "    return {'duplicates': duplicates, 'uniques': uniques}\n",
    "\n",
    "def find_common_elements(df1, df2):\n",
    "    df1_flat = df1.select(pl.col('star1').alias('star')).vstack(\n",
    "        df1.select(pl.col('star2').alias('star'))\n",
    "    )\n",
    "    df2_flat = df2.select(pl.col('star1').alias('star')).vstack(\n",
    "        df2.select(pl.col('star2').alias('star'))\n",
    "    )\n",
    "    common = df1_flat.join(df2_flat, on='star', how='inner')['star'].to_list()\n",
    "    return common if common else None\n",
    "\n",
    "def find_elements(df, element):\n",
    "    mask1 = pl.col('star1') == element\n",
    "    mask2 = pl.col('star2') == element\n",
    "    indices1 = df.select(pl.arg_where(mask1)).to_series().to_list()\n",
    "    indices2 = df.select(pl.arg_where(mask2)).to_series().to_list()\n",
    "\n",
    "    return (indices1 + indices2, [0] * len(indices1) + [1] * len(indices2))\n",
    "\n",
    "def compare_lists(list1, list2):\n",
    "    common = list(set(list1) & set(list2))\n",
    "    return {'common': common, 'unique_in_list1': [x for x in list1 if x not in list2],\n",
    "            'unique_in_list2': [x for x in list2 if x not in list1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной алгоритм\n",
    "\n",
    "def find_triangles(sorted_pairs, dists_catalog, coords_catalog, dist_err, mag_err, mag_info=True):\n",
    "\n",
    "    lists = {}\n",
    "    sources_couple = {}\n",
    "    groups = {}\n",
    "    groups_sources = {}\n",
    "    group_completed = False\n",
    "    num_triangle = 0\n",
    "    count_try = 0\n",
    "    full_len = 0\n",
    "\n",
    "    for d_num in range(len(sorted_pairs)):\n",
    "\n",
    "        distance = sorted_pairs[d_num, 'distance']\n",
    "        mag1 = sorted_pairs[d_num, 'mag1']\n",
    "        mag2 = sorted_pairs[d_num, 'mag2']\n",
    "        source1 = sorted_pairs[d_num, 'id1']\n",
    "        source2 = sorted_pairs[d_num, 'id2']\n",
    "        list_name = f'list_{d_num}_{source1}_{source2}'\n",
    "\n",
    "        dist_matches = dists_catalog.filter(\n",
    "            pl.col('Distance').is_between(distance - dist_err, distance + dist_err)\n",
    "        ).select([\n",
    "            (pl.col('Name1_a').cast(str) + \" \" + pl.col('Name1_b').cast(str)).alias('star1'),\n",
    "            (pl.col('Name2_a').cast(str) + \" \" + pl.col('Name2_b').cast(str)).alias('star2')\n",
    "        ])\n",
    "\n",
    "        if not mag_info:\n",
    "            full_matches = dist_matches\n",
    "\n",
    "        else:\n",
    "            mag1_matches = coords_catalog.filter(\n",
    "                pl.col('Gmag').is_between(mag1 - mag_err, mag1 + mag_err)).select([\n",
    "                (pl.col('Name_a').cast(str) + \" \" + pl.col('Name_b').cast(str)).alias('star')\n",
    "                ])\n",
    "            mag2_matches = coords_catalog.filter(\n",
    "                pl.col('Gmag').is_between(mag2 - mag_err, mag2 + mag_err)).select([\n",
    "                (pl.col('Name_a').cast(str) + \" \" + pl.col('Name_b').cast(str)).alias('star')\n",
    "                ])\n",
    "            full_matches1 = dist_matches.join(mag1_matches, left_on='star1', right_on='star', how='inner')\n",
    "            full_matches1 = full_matches1.join(mag2_matches, left_on='star2', right_on='star', how='inner')\n",
    "            full_matches2 = dist_matches.join(mag1_matches, left_on='star2', right_on='star', how='inner')\n",
    "            full_matches2 = full_matches2.join(mag2_matches, left_on='star1', right_on='star', how='inner')\n",
    "            full_matches = pl.concat([full_matches1, full_matches2])\n",
    "        \n",
    "        full_len += len(full_matches)\n",
    "        lists[list_name] = full_matches\n",
    "        sources_couple[d_num] = [source1, source2]\n",
    "\n",
    "        if d_num == 0 or len(full_matches) == 0:\n",
    "            continue\n",
    "\n",
    "        for num_list in range(d_num):\n",
    "            source3 = sources_couple[num_list][0]\n",
    "            source4 = sources_couple[num_list][1]\n",
    "            duplicates = find_duplicates(source1, source2, source3, source4)\n",
    "\n",
    "            if len(duplicates['duplicates']) == 1:\n",
    "                common_result = find_common_elements(\n",
    "                    lists[list_name],\n",
    "                    lists[f'list_{num_list}_{source3}_{source4}']\n",
    "                )\n",
    "\n",
    "                if common_result:\n",
    "                    for common_star in common_result:\n",
    "                        loc_common_star_list1 = find_elements(lists[list_name], common_star)\n",
    "                        loc_common_star_list2 = find_elements(\n",
    "                            lists[f'list_{num_list}_{source3}_{source4}'], common_star\n",
    "                        )\n",
    "\n",
    "                        for l1, col1 in zip(loc_common_star_list1[0], loc_common_star_list1[1]):\n",
    "                            for l2, col2 in zip(loc_common_star_list2[0], loc_common_star_list2[1]):\n",
    "                                count_try += 1\n",
    "                                triangle = [common_star]\n",
    "                                triangle_sources = [duplicates['duplicates'][0]]\n",
    "\n",
    "                                other_star1 = lists[list_name][l1, 'star2' if col1 == 0 else 'star1']\n",
    "                                triangle.append(other_star1)\n",
    "                                triangle_sources.append(next(x for x in [source1, source2] if x != duplicates['duplicates'][0]))\n",
    "\n",
    "                                other_star2 = lists[f'list_{num_list}_{source3}_{source4}'][l2, 'star2' if col2 == 0 else 'star1']\n",
    "                                triangle.append(other_star2)\n",
    "                                triangle_sources.append(next(x for x in [source3, source4] if x != duplicates['duplicates'][0]))\n",
    "\n",
    "                                star2_name_a, star2_name_b = map(float, triangle[1].split())\n",
    "                                star3_name_a, star3_name_b = map(float, triangle[2].split())\n",
    "\n",
    "                                third_side_stars = dists_catalog.filter(\n",
    "                                    ((pl.col('Name1_a') == star2_name_a) &\n",
    "                                    (pl.col('Name1_b') == star2_name_b) &\n",
    "                                    (pl.col('Name2_a') == star3_name_a) &\n",
    "                                    (pl.col('Name2_b') == star3_name_b)) |\n",
    "                                    ((pl.col('Name1_a') == star3_name_a) &\n",
    "                                    (pl.col('Name1_b') == star3_name_b) &\n",
    "                                    (pl.col('Name2_a') == star2_name_a) &\n",
    "                                    (pl.col('Name2_b') == star2_name_b))\n",
    "                                ).select('Distance').to_series().to_list()\n",
    "\n",
    "                                third_side_sources = sorted_pairs.filter(\n",
    "                                    ((pl.col('id1') == duplicates['uniques'][0]) &\n",
    "                                    (pl.col('id2') == duplicates['uniques'][1])) |\n",
    "                                    ((pl.col('id2') == duplicates['uniques'][0]) &\n",
    "                                    (pl.col('id1') == duplicates['uniques'][1]))\n",
    "                                ).select('distance').to_series().to_list()\n",
    "\n",
    "                                if third_side_stars and third_side_sources:\n",
    "                                    if abs(third_side_stars[0] - third_side_sources[0]) < dist_err:\n",
    "                                        #print(\"New triangle is built!\", d_num)\n",
    "                                        num_triangle += num_triangle\n",
    "\n",
    "                                        found_in_group = False\n",
    "                                        for group_id, group_stars in list(groups.items()):\n",
    "                                            stars_in_group = compare_lists(triangle, group_stars)\n",
    "                                            sources_in_group = compare_lists(triangle_sources, groups_sources[group_id])\n",
    "                                            if stars_in_group['common']:\n",
    "                                                found_in_group = True\n",
    "                                                for i, new_star in enumerate(triangle):\n",
    "                                                    new_source = triangle_sources[i]\n",
    "                                                    if new_star not in group_stars:\n",
    "                                                        group_stars.append(new_star)\n",
    "                                                    if new_source not in groups_sources[group_id]:\n",
    "                                                        groups_sources[group_id].append(new_source)\n",
    "\n",
    "                                        if not found_in_group:\n",
    "                                            groups[num_triangle - 1] = list(triangle)\n",
    "                                            groups_sources[num_triangle - 1] = list(triangle_sources)\n",
    "\n",
    "                                        for group_id, group_stars in groups.items():\n",
    "                                            if len(group_stars) > 3 and len(groups_sources[group_id]) > 3:\n",
    "\n",
    "                                                #print(\"Group is completed!\\n\")\n",
    "                                                valid_group_sources = list(groups_sources[group_id])\n",
    "                                                valid_group = list(group_stars)\n",
    "                                                main_star = [valid_group_sources[0], valid_group[0]]\n",
    "                                                return main_star, valid_group, valid_group_sources#, d_num+1, count_try, full_len \n",
    "                                                                                                  # это величины для тестирования: \n",
    "                                                                                                  # \"Обработано пар фотоцентров\" d_num+1, \n",
    "                                                                                                  # \"Количество запросов к БД\" count_try, \n",
    "                                                                                                  # \"Объём запросов\" full_len\n",
    "     \n",
    "    print(\"Identification failed with no completed group\\n\")\n",
    "    return None, [], []#, len(sorted_pairs)+1, count_try, full_len - те же величины для тестирования\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для отождествления навигационных звёзд (верификация)\n",
    "\n",
    "def create_custom_wcs(ra, dec, x, y, projection='TAN'):\n",
    "    wcs = WCS(naxis=2)\n",
    "    wcs.wcs.crpix = [x, y]\n",
    "    wcs.wcs.crval = [ra, dec]\n",
    "    wcs.wcs.cdelt = [-Scale, Scale]\n",
    "    wcs.wcs.ctype = [f\"RA---{projection}\", f\"DEC--{projection}\"]\n",
    "    return wcs\n",
    "\n",
    "def find_frame_center(star_ra, star_dec, star_x, star_y):\n",
    "    wcs_temp = create_custom_wcs(star_ra, star_dec, star_x, star_y)\n",
    "    cent_x = Image_size / 2.0\n",
    "    cent_y = Image_size / 2.0\n",
    "    cent_ra, cent_dec = wcs_temp.all_pix2world(cent_x, cent_y, 0)\n",
    "    wcs_cent = create_custom_wcs(cent_ra, cent_dec, cent_x, cent_y)\n",
    "    return cent_ra, cent_dec, wcs_cent\n",
    "\n",
    "def w2p(df, cent_ra, cent_dec):\n",
    "    wcs = create_custom_wcs(cent_ra, cent_dec, Image_size / 2.0, Image_size / 2.0)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', FITSFixedWarning)\n",
    "        x_pixels, y_pixels = wcs.all_world2pix(df['RA'].to_numpy(), df['Dec'].to_numpy(), 0)\n",
    "\n",
    "    result_df = df.with_columns([\n",
    "        pl.Series('x_pixel', x_pixels),\n",
    "        pl.Series('y_pixel', y_pixels)\n",
    "    ]).filter(\n",
    "        (pl.col('x_pixel') >= 0) &\n",
    "        (pl.col('x_pixel') < Image_size) &\n",
    "        (pl.col('y_pixel') >= 0) &\n",
    "        (pl.col('y_pixel') < Image_size)\n",
    "    )\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def find_star_coords(star, coords_catalog, sources_df):\n",
    "    star_name_a, star_name_b = map(float, star[1].split())\n",
    "    ra_dec = coords_catalog.filter(\n",
    "        (pl.col('Name_a') == star_name_a) & (pl.col('Name_b') == star_name_b)\n",
    "    ).select(['RA', 'Dec']).row(0)\n",
    "\n",
    "    return ra_dec[0], ra_dec[1]\n",
    "\n",
    "def nav_stars_on_frame(df, ra_cent, de_cent, rad, mag):\n",
    "    half_side = round(rad, 1)\n",
    "    ra_min = ra_cent - half_side\n",
    "    ra_max = ra_cent + half_side\n",
    "    dec_min = de_cent - half_side\n",
    "    dec_max = de_cent + half_side\n",
    "\n",
    "    nav_stars_df = df.filter(\n",
    "        (pl.col('Gmag') < mag) &\n",
    "        (pl.col('RA') >= ra_min) & (pl.col('RA') <= ra_max) &\n",
    "        (pl.col('Dec') >= dec_min) & (pl.col('Dec') <= dec_max)\n",
    "    ).drop(['X', 'Y'])\n",
    "\n",
    "    return nav_stars_df\n",
    "\n",
    "def kdtree_match(stars, sources, tolerance=5):\n",
    "    coords1 = stars.select(['x_pixel', 'y_pixel']).to_numpy()\n",
    "    coords2 = sources.select(['xcentroid', 'ycentroid']).to_numpy()\n",
    "    tree = KDTree(coords2)\n",
    "    distances, indices = tree.query(coords1, distance_upper_bound=tolerance)\n",
    "\n",
    "    matches = []\n",
    "    for i, (dist, idx) in enumerate(zip(distances, indices)):\n",
    "        if idx < len(coords2) and dist <= tolerance:\n",
    "            matches.append({\n",
    "                'x_star': coords1[i, 0],\n",
    "                'y_pixel': coords1[i, 1],\n",
    "                'xcentroid': coords2[idx, 0],\n",
    "                'ycentroid': coords2[idx, 1],\n",
    "                'distance': dist\n",
    "            })\n",
    "    return pl.DataFrame(matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка каталогов\n",
    "\n",
    "coords_col_name = ['X', 'Y', 'Gmag', 'RA', 'Dec', 'RA_IRAF', 'Dec_IRAF', 'Name_a', 'Name_b']\n",
    "dists_col_name = ['Distance', 'Name1_a', 'Name1_b', 'Name2_a', 'Name2_b']\n",
    "\n",
    "coords_catalog, coords_catalog_filename = upload_file(\n",
    "    \"coords_g10.parquet\",\n",
    "    f\"Uploading catalog with coordinates...\",\n",
    "    coords_col_name\n",
    ")\n",
    "\n",
    "dists_catalog, dists_catalog_filename = upload_file(\n",
    "    \"dists_g10.parquet\",\n",
    "    f\"Uploading catalog with distances...\\n\",\n",
    "    dists_col_name\n",
    ")\n",
    "\n",
    "print(f\"Number of stars: {len(coords_catalog)}\")\n",
    "print(f\"Number of distances: {len(dists_catalog)}\\n\")\n",
    "print(\"Coords catalog head:\")\n",
    "print(coords_catalog.head())\n",
    "print(\"Dists catalog head:\")\n",
    "print(dists_catalog.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angular_distance(ra1_deg, dec1_deg, ra2_deg, dec2_deg):\n",
    "\n",
    "    ra1_rad = np.radians(ra1_deg)\n",
    "    dec1_rad = np.radians(dec1_deg)\n",
    "    ra2_rad = np.radians(ra2_deg)\n",
    "    dec2_rad = np.radians(dec2_deg)\n",
    "\n",
    "    delta_ra = np.abs(ra1_deg - ra2_deg)\n",
    "    delta_ra = np.minimum(delta_ra, 360 - delta_ra)\n",
    "    delta_ra_rad = np.radians(delta_ra)\n",
    "\n",
    "    cos_distance = (\n",
    "        np.sin(dec1_rad) * np.sin(dec2_rad) +\n",
    "        np.cos(dec1_rad) * np.cos(dec2_rad) * np.cos(delta_ra_rad)\n",
    "    )\n",
    "    cos_distance = np.clip(cos_distance, -1.0, 1.0)\n",
    "    distance_rad = np.arccos(cos_distance)\n",
    "    distance_deg = np.degrees(distance_rad)\n",
    "    \n",
    "    return distance_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(sources_table, theta_max):\n",
    "\n",
    "    coords = sources_table.select(['RA', 'Dec']).to_numpy()\n",
    "    mag = sources_table.select(['Gmag']).to_numpy()\n",
    "    names = sources_table.select(['ID']).to_numpy()\n",
    "    \n",
    "    tree = KDTree(coords)\n",
    "    pairs = tree.query_pairs(r=theta_max*1.5, output_type='ndarray')\n",
    "    \n",
    "    result = []\n",
    "    k = 0\n",
    "    \n",
    "    i, j = pairs[:, 0], pairs[:, 1]\n",
    "    ra1, dec1 = coords[i, 0], coords[i, 1]\n",
    "    ra2, dec2 = coords[j, 0], coords[j, 1]\n",
    "    theta = calculate_angular_distance(ra1, dec1, ra2, dec2)\n",
    "    \n",
    "    valid = (theta > 0) & (theta <= theta_max)\n",
    "    i, j, theta = i[valid], j[valid], theta[valid]\n",
    "\n",
    "    for idx in range(len(i)):\n",
    "        result.append({\n",
    "            'distance': theta[idx],\n",
    "            'sum_Gmag': mag[i[idx]] + mag[j[idx]],\n",
    "            'mag1': mag[i[idx]],\n",
    "            'mag2': mag[j[idx]],\n",
    "            'id1': names[i[idx]],\n",
    "            'id2': names[j[idx]]\n",
    "        })\n",
    "        k=k+1\n",
    "    \n",
    "    unsorted_sources = pl.DataFrame(result, schema={\n",
    "        'distance': pl.Float64,\n",
    "        'sum_Gmag': pl.Float64,\n",
    "        'mag1': pl.Float64,\n",
    "        'mag2': pl.Float64,\n",
    "        'id1': pl.Int64,\n",
    "        'id2': pl.Int64,\n",
    "    })\n",
    "    unsorted_sources = unsorted_sources.unique(keep=\"first\")\n",
    "    sorted_sources = unsorted_sources.sort('sum_Gmag', descending=False)\n",
    "    sorted_sources = sorted_sources.drop(['sum_Gmag'])\n",
    "    \n",
    "    return sorted_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_measurement_error(df, columns=['Gmag', 'RA', 'Dec'], error_coords=0.001, error_mag=0.1, error_type='absolute'):\n",
    "\n",
    "    result = df.clone()\n",
    "\n",
    "    for i, col in enumerate(columns):\n",
    "        values = df[col].to_numpy()\n",
    "        \n",
    "        if error_type == 'relative':\n",
    "            if i == 0:\n",
    "                std_dev = np.abs(values) * error_mag/3.\n",
    "            else:\n",
    "                std_dev = np.abs(values) * error_coords/3.\n",
    "                \n",
    "        else:\n",
    "            if i == 0:\n",
    "                std_dev = error_mag/3.\n",
    "            else:\n",
    "                std_dev = error_coords/3.\n",
    "        \n",
    "        noise = np.random.normal(0, std_dev, len(values))\n",
    "        noisy_values = values + noise\n",
    "        result = result.with_columns(pl.lit(noisy_values).alias(col))\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "id": "8RAUtLYo7LmI",
    "outputId": "cb72f23a-1750-4769-9203-9ed47b5f229c"
   },
   "outputs": [],
   "source": [
    "# Основные параметры\n",
    "\n",
    "Rad = 1\n",
    "Image_size = 1024\n",
    "Catalog_name = \"DSS\"\n",
    "Scale = 0.7 / (Image_size/2.) # размеря пикселя в градусах\n",
    "\n",
    "Theta_max = 0.7\n",
    "\n",
    "# Загрузка изображения и обработка источников на нём (сделано для виртуального кадра)\n",
    "\n",
    "RA_true, Dec_true = get_random_in_square(0, 358, -68, 68)\n",
    "print(f\"True coords: RA_true = {RA_true:.1f}°, Dec_true = {Dec_true:.1f}°\")\n",
    "sources = nav_stars_on_frame(coords_catalog, RA_true, Dec_true, rad=Rad, mag=10)\n",
    "sources = add_measurement_error(sources, error_coords=Scale, error_mag=0.1)\n",
    "if len(sources) > 13:\n",
    "    print(f\"Number of sources: {len(sources)}\")\n",
    "    sources_id = []\n",
    "    for idx in range(len(sources)):\n",
    "        sources_id.append(idx+1)\n",
    "    sources = sources.with_columns(pl.Series('ID', sources_id))\n",
    "    sorted_pairs = compute_distances(sources, Theta_max)\n",
    "else:\n",
    "    print(f\"Image is invalid, {len(sources)} sources\")\n",
    "    sources = sources.clear()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Применение основного алгоритма\n",
    "\n",
    "Dist_err = Scale\n",
    "Mag_err = 0.1\n",
    "start_time = time.time()\n",
    "main_star, valid_group, valid_group_sources = find_triangles(sorted_pairs, dists_catalog, coords_catalog, Dist_err, Mag_err, mag_info=True)\n",
    "elapsed = time.time() - start_time \n",
    "\n",
    "# Вывод результатов\n",
    "if main_star:\n",
    "    print(f\"Main star: {main_star}\")\n",
    "    print(f\"Valid star group: {valid_group}\")\n",
    "    print(f\"Valid sources group: {valid_group_sources}\\n\")\n",
    "\n",
    "    # Применяется, если используется виртуальный кадр; если нет - переход к следующей ячейке\n",
    "    # count_matches = []\n",
    "    # for i, star in enumerate(valid_group):\n",
    "    #     star_name_a, star_name_b = map(float, star.split())\n",
    "    #     star_match = sources.filter((pl.col('Name_a') == star_name_a) & (pl.col('Name_b') == star_name_b)).select('Name_a', 'Name_b')\n",
    "    #     if len(star_match) != 0:\n",
    "    #         count_matches.append(str(star_match['Name_a'][0]) + \" \" + str(star_match['Name_b'][0]))\n",
    "    # if len(count_matches) == len(valid_group):\n",
    "    #     print(\"Identification is successful!\")\n",
    "    #     print(count_matches)\n",
    "    # else:\n",
    "    #     print(\"Identification failed\")\n",
    "    #     print(count_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qfw9P8jJ93H5",
    "outputId": "37eaabf0-7e9c-4ec5-b3f6-f83a75fdff74"
   },
   "outputs": [],
   "source": [
    "# Нахождение координат центра кадра и их верификация с помощью других навигационных звёзд на кадре\n",
    "\n",
    "Mag_lim = 10.0\n",
    "Coords_err = 1\n",
    "\n",
    "Shift = True # Если известно, что есть сдвиг в изображении\n",
    "\n",
    "# Нахождение центра кадра\n",
    "\n",
    "main_star_ra, main_star_dec = find_star_coords(main_star, coords_catalog, sources_df) # main_star_x, main_star_y\n",
    "center_ra, center_dec, wcs_center = find_frame_center(main_star_ra, main_star_dec, main_star_x, main_star_y)\n",
    "\n",
    "if Shift:\n",
    "    head = WCS(header=image.header)\n",
    "    ra_image, dec_image = head.all_pix2world(Image_size / 2.0, Image_size / 2.0, 0)\n",
    "    delta_ra = RA_true - ra_image\n",
    "    delta_dec = Dec_true - dec_image\n",
    "    RA_center = center_ra + delta_ra\n",
    "    Dec_center = center_dec + delta_dec\n",
    "    RA_err = abs(main_star_ra - RA_true) # RA_center\n",
    "    Dec_err = abs(main_star_dec - Dec_true) # Dec_center\n",
    "else:\n",
    "    RA_center = center_ra\n",
    "    Dec_center = center_dec\n",
    "\n",
    "print(f\"Found frame center: RA = {main_star_ra:.6f}°, Dec = {main_star_dec:.6f}°\")\n",
    "print(f\"True coords: RA_true = {RA_true:.1f}°, Dec_true = {Dec_true:.1f}°\")\n",
    "print(f\"Discrepancy: RA_err = {RA_err:.6f}°, Dec_err = {Dec_err:.6f}°\")\n",
    "\n",
    "# Верификация\n",
    "\n",
    "if RA_err < Coords_err and Dec_err < Coords_err:\n",
    "    ident_status = \"Identification is successful!\"\n",
    "    print(ident_status)\n",
    "    nav_stars = nav_stars_on_frame(coords_catalog, center_ra, center_dec, Rad, Mag_lim)\n",
    "    K = len(nav_stars)\n",
    "    nav_pix = w2p(nav_stars, center_ra, center_dec)\n",
    "    nav_matches = kdtree_match(nav_pix, sources_df, tolerance=10)\n",
    "\n",
    "    if len(nav_matches) > K/2.:\n",
    "        valid_status = \"Validation is successful!\"\n",
    "        ident_status = \"Identification is successful!\"\n",
    "        print(ident_status)\n",
    "        print(f\"Found configuration of stars: {valid_group}\")\n",
    "    else:\n",
    "        valid_status = \"Validation failed\"\n",
    "        valid_flag = False\n",
    "        print(valid_status)\n",
    "else:\n",
    "    ident_status = \"Identification failed\"\n",
    "    print(ident_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка файла с результатами\n",
    "\n",
    "info_filename = \"result.txt\"\n",
    "if not os.path.exists(\"algorithm_result\"):\n",
    "    os.makedirs(\"algorithm_result\")\n",
    "with open(os.path.join(\"algorithm_result\", info_filename), 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(ident_status + \"\\n\")\n",
    "    f.write(valid_status + \"\\n\\n\")\n",
    "    f.write(f\"Found frame center: RA = {RA_center:.6f}°, Dec = {Dec_center:.6f}°\\n\")\n",
    "    f.write(f\"True coordinates: RA_true = {RA_true:.6f}°, Dec_true = {Dec_true:.6f}°\\n\")\n",
    "    f.write(f\"Discrepancy: RA_err = {RA_err:.6f}°, Dec_err = {Dec_err:.6f}°\\n\")\n",
    "    f.write(f\"Found configuration of stars: {valid_group} (first star is common)\\n\") \n",
    "    f.write(f\"Corresponding sources on the image: {valid_group_sources}\\n\")\n",
    "    f.write(f\"Number of triangles constructed: {num_built_triangles}\\n\")\n",
    "    f.write(f\"Distances scanned: {num_dist}\\n\")\n",
    "    f.write(f\"Matches of navigation stars on the frame: {len(nav_matches)}/{K}\\n\\n\")\n",
    "    f.write(f\"Elapsed time per scan: {elapsed:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
